{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9i4wPmOq9Fo",
    "outputId": "aceb2dc7-fb24-435b-bba6-67d639b37f0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim \n",
    "# !pip install pymorphy2\n",
    "# !pip install summa\n",
    "# !pip install python-rake\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "from gensim.summarization import keywords as kw\n",
    "from summa import keywords\n",
    "import string\n",
    "import re\n",
    "import RAKE\n",
    "import nltk\n",
    "import os\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "rake = RAKE.Rake(stop)\n",
    "from nltk.parse import DependencyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptVm3bl_xlEm",
    "outputId": "1115a80f-64e2-4136-f10b-0eadc668cbe8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbPH7H4jilUE"
   },
   "source": [
    "датасет 500N-KPCrowd-v1.1 брала здесь: https://github.com/LIAAD/KeywordExtractor-Datasets/tree/master/datasets\n",
    "\n",
    "в предоставляемом архиве тексты лежат в папке docsutf8, ключевые слова к ним находятся в папке keys. Файлы с текстами и соответствующими ключевыми совами имеют одинаковые называния. \n",
    "Ключевые слова для каждого текста записаны в отдельный файл через \\n\n",
    "ключевые слова могут включать в себя именную группу или клаузу\n",
    "\n",
    "для составления своего мини-корпуса я взяла оттуда 15 текстов на три разныех темы: бизнесс, мода, исскуство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "id": "GytnE6UZ1g38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading UDPipe model: done.\n"
     ]
    }
   ],
   "source": [
    "!C:\\Users\\User\\Desktop\\avtob\\avtobreya\\udpipe-1.2.0-bin\\bin-win64\\udpipe --input horizontal --output conllu \\\n",
    "--tokenize --tag --parse \\\n",
    "C:\\Users\\User\\Desktop\\avtob\\avtobreya\\english-ewt-ud-2.5-191206.udpipe \\\n",
    "< C:/Users/User/Desktop/avtob/avtobreya/key_words/500N-KPCrowd-v1.1/mini-corpus/text/fashion-20910434.txt > mini-corpus\\synt_models_en\\fashion-20910434.conllu\n",
    "# записала 15 моделей для каждоого текста в папку \\synt_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "скачиваю тексты, создаю корпус вида corpus(text, key, my_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "id": "qTlF--7n7BpE"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "cwd = os.getcwd().replace('\\\\', '/')\n",
    "path_text = cwd + '/mini-corpus/text/'\n",
    "path_key = cwd + '/mini-corpus/keys/'\n",
    "path_my_key = cwd + '/mini-corpus/my_keys/'\n",
    "path_model = cwd + '/mini-corpus/synt_models_en/'\n",
    "\n",
    "dir_texts= os.listdir(path_text)\n",
    "\n",
    "for file in dir_texts:\n",
    "    base=os.path.basename(file)\n",
    "#     print(path_text + os.path.splitext(base)[0])\n",
    "    with open(path_text + os.path.splitext(base)[0] + '.txt', 'r', encoding = 'utf-8') as f:\n",
    "        text = f.read()\n",
    "    with open(path_key + os.path.splitext(base)[0] + '.key', 'r', encoding = 'utf-8') as f:\n",
    "        key = f.read().split('\\n')\n",
    "    with open(path_my_key + os.path.splitext(base)[0] + '.key', 'r', encoding = 'utf-8') as f:\n",
    "        my_key = f.read().split('\\n')\n",
    "          \n",
    "    corpus.append((text, key, my_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "нахожу пересечение своей разметки и уже готовой. это будет эталоном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_etalon():\n",
    "    etal = [x[1] for x in corpus]\n",
    "    my_etal = [x[2] for x in corpus]\n",
    "\n",
    "    etalon = []\n",
    "    for ind, et in enumerate(etal):\n",
    "\n",
    "        etalon_set = list(set(et) & set(my_etal[ind]))\n",
    "        etalon.append([x.lower() for x in etalon_set])\n",
    "        \n",
    "    return etalon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "id": "R9Pmp5bzp-0m"
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        lemmas.append(\n",
    "            m.parse(t)[0].normal_form)\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разные способы выделения ключевых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "id": "IVBitb7brApt"
   },
   "outputs": [],
   "source": [
    "def create_corpus_auto_keys(corpus):\n",
    "    list_ra = []\n",
    "    list_TextRank = []\n",
    "    list_summa = []\n",
    "    for text in corpus:\n",
    "        text = normalize_text(text[0])\n",
    "        \n",
    "        ra = rake.run(text, maxWords=3, minFrequency=2)\n",
    "        ra = [r[0] for r in ra]\n",
    "        \n",
    "        TextRank = kw(text, pos_filter=[], scores=True)\n",
    "        TextRank = [t[0] for t in TextRank]\n",
    "        \n",
    "        summa = keywords.keywords(text, additional_stopwords=stop, scores=True)\n",
    "        summa = [s[0] for s in summa]\n",
    "        \n",
    "        list_ra.append(ra)\n",
    "        list_TextRank.append(TextRank)\n",
    "        list_summa.append(summa)\n",
    "\n",
    "    return list_ra, list_TextRank, list_summa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создаю свой способ поиска ключевых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FILTER_RELS = ['punct', 'conj', 'parataxis']\n",
    "def get_subtree(nodes, node):\n",
    "    if not nodes[node]['deps']:\n",
    "        return [node]\n",
    "    else:\n",
    "        return [node] + [get_subtree(nodes, dep) for rel in nodes[node]['deps'] \n",
    "                         if rel not in _FILTER_RELS\n",
    "                         for dep in nodes[node]['deps'][rel]]\n",
    "    \n",
    "    \n",
    "def flatten(l):\n",
    "    flat = []\n",
    "    for el in l:\n",
    "        if not isinstance(el, list):\n",
    "            flat.append(el)\n",
    "        else:\n",
    "            flat += flatten(el)\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key_words(t, synt_mor = False):\n",
    "    result = []\n",
    "    try:\n",
    "        np_list = []\n",
    "        g = DependencyGraph(t, top_relation_label='root')\n",
    "        for n in g.nodes:\n",
    "            if g.nodes[n]['ctag'] == 'NOUN' or g.nodes[n]['ctag'] == 'PROPN':\n",
    "                np = list(sorted(flatten(get_subtree(g.nodes, n))))\n",
    "                np_list.append(\n",
    "                    ' '.join([g.nodes[i]['word'].lower() for i in np]))\n",
    "        if synt_mor:\n",
    "            list_names = find_adg_noun(g)\n",
    "            np_list += [x.lower() for x in list_names]\n",
    "                \n",
    "    except ValueError:\n",
    "        print('pass')\n",
    "    return np_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "это фильтр для поиска именных групп типа ADJ + NOUN.\n",
    "ключевые слова, найденные таким образом добавляются в конец списка, если \n",
    "функции create_key_words() передать аргумент with_my_rules = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_adg_noun(g):\n",
    "    nouns = [('', '', '')]\n",
    "    ret = []\n",
    "    for n in g.nodes:\n",
    "        b = g.get_by_address(n)['word']\n",
    "        d = g.get_by_address(n)['ctag']\n",
    "        if  (d == 'PROPN' or d == 'NOUN') and nouns[-1][2] == 'ADJ':\n",
    "            nouns[-1] = nouns[-1][0] + ' ' + b\n",
    "            ret.append(nouns[-1])\n",
    "\n",
    "        nouns.append((b, n, d))\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "функция проходится по всем файлам и находит ключевые слова для каждого\n",
    "на основе разметри udpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_key_words(with_my_rules = False):\n",
    "    corpus_udpipe = []\n",
    "    curr = os.getcwd()\n",
    "    for name_file in os.listdir(path_model):\n",
    "        trees = []\n",
    "\n",
    "        with open(curr + '\\\\mini-corpus\\\\synt_models_en\\\\' + name_file, 'r', encoding = 'utf-8') as f:\n",
    "            parsed_sents = f.read().split('\\n\\n')\n",
    "            corpus_words_per_senr = []\n",
    "            for i, sent in enumerate(parsed_sents):\n",
    "\n",
    "                tree = [line for line in sent.split('\\n') if line and line[0] != '#']\n",
    "                result = find_key_words(tree, with_my_rules)\n",
    "                corpus_words_per_senr += result\n",
    "            corpus_udpipe.append(corpus_words_per_senr)\n",
    "    return corpus_udpipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "считает метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_metrics(i, corpus):\n",
    "    right_keys = list(set(etalon[i]) & set(x for x in corpus[i] if len(x.split(' ')) < 3))\n",
    "    \n",
    "    if right_keys == []:\n",
    "        return 0, 0, 0\n",
    "    else:\n",
    "        all_keys_find = [x for x in corpus[i] if len(x.split(' ')) < 3]\n",
    "        precision = len(right_keys) / len(all_keys_find)\n",
    "        recall = len(right_keys) / len(etalon[i])\n",
    "        f1 = 2*((precision*recall) / (precision + recall))\n",
    "        return round(precision, 2), round(recall, 2), round(f1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['мой способ', 'rake', 'TextRank', 'summa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "etalon = create_etalon()\n",
    "corpus_udpipe = create_key_words()\n",
    "list_ra, list_TextRank, list_summa = create_corpus_auto_keys(corpus)\n",
    "\n",
    "for i in range(len(etalon)):\n",
    "    df.loc[i,'мой способ'] = count_metrics(i, corpus_udpipe)\n",
    "    df.loc[i]['rake'] = count_metrics(i, list_ra)\n",
    "    df.loc[i]['TextRank'] = count_metrics(i, list_TextRank)\n",
    "    df.loc[i]['summa'] = count_metrics(i, list_summa)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "без примерения фильтра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>мой способ</th>\n",
       "      <th>rake</th>\n",
       "      <th>TextRank</th>\n",
       "      <th>summa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.1, 0.21, 0.14)</td>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>(0.24, 0.11, 0.15)</td>\n",
       "      <td>(0.25, 0.11, 0.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.19, 0.17, 0.18)</td>\n",
       "      <td>(0.67, 0.1, 0.17)</td>\n",
       "      <td>(0.23, 0.07, 0.11)</td>\n",
       "      <td>(0.4, 0.14, 0.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.08, 0.27, 0.13)</td>\n",
       "      <td>(0.31, 0.12, 0.17)</td>\n",
       "      <td>(0.47, 0.24, 0.32)</td>\n",
       "      <td>(0.43, 0.27, 0.33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.18, 0.19, 0.19)</td>\n",
       "      <td>(0.67, 0.06, 0.1)</td>\n",
       "      <td>(0.25, 0.06, 0.09)</td>\n",
       "      <td>(0.38, 0.08, 0.14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.06, 0.18, 0.09)</td>\n",
       "      <td>(0.11, 0.06, 0.08)</td>\n",
       "      <td>(0.06, 0.06, 0.06)</td>\n",
       "      <td>(0.06, 0.06, 0.06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.03, 0.12, 0.04)</td>\n",
       "      <td>(0.1, 0.05, 0.07)</td>\n",
       "      <td>(0.07, 0.1, 0.09)</td>\n",
       "      <td>(0.08, 0.1, 0.09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.12, 0.23, 0.15)</td>\n",
       "      <td>(0.09, 0.03, 0.04)</td>\n",
       "      <td>(0.37, 0.17, 0.24)</td>\n",
       "      <td>(0.33, 0.17, 0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.12, 0.23, 0.16)</td>\n",
       "      <td>(0.5, 0.19, 0.28)</td>\n",
       "      <td>(0.31, 0.15, 0.21)</td>\n",
       "      <td>(0.31, 0.15, 0.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.07, 0.19, 0.1)</td>\n",
       "      <td>(0.18, 0.07, 0.1)</td>\n",
       "      <td>(0.23, 0.16, 0.19)</td>\n",
       "      <td>(0.23, 0.16, 0.19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.13, 0.14, 0.14)</td>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>(0.17, 0.07, 0.1)</td>\n",
       "      <td>(0.29, 0.07, 0.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(0.05, 0.26, 0.08)</td>\n",
       "      <td>(0.11, 0.09, 0.1)</td>\n",
       "      <td>(0.14, 0.21, 0.17)</td>\n",
       "      <td>(0.14, 0.21, 0.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(0.14, 0.24, 0.17)</td>\n",
       "      <td>(0.38, 0.1, 0.16)</td>\n",
       "      <td>(0.44, 0.16, 0.23)</td>\n",
       "      <td>(0.42, 0.16, 0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(0.08, 0.26, 0.12)</td>\n",
       "      <td>(0.17, 0.08, 0.11)</td>\n",
       "      <td>(0.2, 0.16, 0.18)</td>\n",
       "      <td>(0.19, 0.16, 0.18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(0.07, 0.07, 0.07)</td>\n",
       "      <td>(0.8, 0.07, 0.14)</td>\n",
       "      <td>(0.42, 0.15, 0.22)</td>\n",
       "      <td>(0.42, 0.15, 0.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(0.16, 0.15, 0.15)</td>\n",
       "      <td>(0.25, 0.01, 0.03)</td>\n",
       "      <td>(0.3, 0.1, 0.15)</td>\n",
       "      <td>(0.23, 0.07, 0.11)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            мой способ                rake            TextRank  \\\n",
       "0    (0.1, 0.21, 0.14)           (0, 0, 0)  (0.24, 0.11, 0.15)   \n",
       "1   (0.19, 0.17, 0.18)   (0.67, 0.1, 0.17)  (0.23, 0.07, 0.11)   \n",
       "2   (0.08, 0.27, 0.13)  (0.31, 0.12, 0.17)  (0.47, 0.24, 0.32)   \n",
       "3   (0.18, 0.19, 0.19)   (0.67, 0.06, 0.1)  (0.25, 0.06, 0.09)   \n",
       "4   (0.06, 0.18, 0.09)  (0.11, 0.06, 0.08)  (0.06, 0.06, 0.06)   \n",
       "5   (0.03, 0.12, 0.04)   (0.1, 0.05, 0.07)   (0.07, 0.1, 0.09)   \n",
       "6   (0.12, 0.23, 0.15)  (0.09, 0.03, 0.04)  (0.37, 0.17, 0.24)   \n",
       "7   (0.12, 0.23, 0.16)   (0.5, 0.19, 0.28)  (0.31, 0.15, 0.21)   \n",
       "8    (0.07, 0.19, 0.1)   (0.18, 0.07, 0.1)  (0.23, 0.16, 0.19)   \n",
       "9   (0.13, 0.14, 0.14)           (0, 0, 0)   (0.17, 0.07, 0.1)   \n",
       "10  (0.05, 0.26, 0.08)   (0.11, 0.09, 0.1)  (0.14, 0.21, 0.17)   \n",
       "11  (0.14, 0.24, 0.17)   (0.38, 0.1, 0.16)  (0.44, 0.16, 0.23)   \n",
       "12  (0.08, 0.26, 0.12)  (0.17, 0.08, 0.11)   (0.2, 0.16, 0.18)   \n",
       "13  (0.07, 0.07, 0.07)   (0.8, 0.07, 0.14)  (0.42, 0.15, 0.22)   \n",
       "14  (0.16, 0.15, 0.15)  (0.25, 0.01, 0.03)    (0.3, 0.1, 0.15)   \n",
       "\n",
       "                 summa  \n",
       "0   (0.25, 0.11, 0.15)  \n",
       "1    (0.4, 0.14, 0.21)  \n",
       "2   (0.43, 0.27, 0.33)  \n",
       "3   (0.38, 0.08, 0.14)  \n",
       "4   (0.06, 0.06, 0.06)  \n",
       "5    (0.08, 0.1, 0.09)  \n",
       "6   (0.33, 0.17, 0.23)  \n",
       "7   (0.31, 0.15, 0.21)  \n",
       "8   (0.23, 0.16, 0.19)  \n",
       "9   (0.29, 0.07, 0.11)  \n",
       "10  (0.14, 0.21, 0.17)  \n",
       "11  (0.42, 0.16, 0.23)  \n",
       "12  (0.19, 0.16, 0.18)  \n",
       "13  (0.42, 0.15, 0.22)  \n",
       "14  (0.23, 0.07, 0.11)  "
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "etalon = create_etalon()\n",
    "corpus_udpipe = create_key_words(with_my_rules = True)\n",
    "list_ra, list_TextRank, list_summa = create_corpus_auto_keys(corpus)\n",
    "\n",
    "for i in range(len(etalon)):\n",
    "    df.loc[i,'мой способ'] = count_metrics(i, corpus_udpipe)\n",
    "    df.loc[i]['rake'] = count_metrics(i, list_ra)\n",
    "    df.loc[i]['TextRank'] = count_metrics(i, list_TextRank)\n",
    "    df.loc[i]['summa'] = count_metrics(i, list_summa)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с применением фильтра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>мой способ</th>\n",
       "      <th>rake</th>\n",
       "      <th>TextRank</th>\n",
       "      <th>summa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.09, 0.21, 0.13)</td>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>(0.24, 0.11, 0.15)</td>\n",
       "      <td>(0.25, 0.11, 0.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.17, 0.17, 0.17)</td>\n",
       "      <td>(0.67, 0.1, 0.17)</td>\n",
       "      <td>(0.23, 0.07, 0.11)</td>\n",
       "      <td>(0.4, 0.14, 0.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.08, 0.27, 0.12)</td>\n",
       "      <td>(0.31, 0.12, 0.17)</td>\n",
       "      <td>(0.47, 0.24, 0.32)</td>\n",
       "      <td>(0.43, 0.27, 0.33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.17, 0.19, 0.18)</td>\n",
       "      <td>(0.67, 0.06, 0.1)</td>\n",
       "      <td>(0.25, 0.06, 0.09)</td>\n",
       "      <td>(0.38, 0.08, 0.14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.05, 0.18, 0.08)</td>\n",
       "      <td>(0.11, 0.06, 0.08)</td>\n",
       "      <td>(0.06, 0.06, 0.06)</td>\n",
       "      <td>(0.06, 0.06, 0.06)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.02, 0.12, 0.04)</td>\n",
       "      <td>(0.1, 0.05, 0.07)</td>\n",
       "      <td>(0.07, 0.1, 0.09)</td>\n",
       "      <td>(0.08, 0.1, 0.09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.1, 0.23, 0.14)</td>\n",
       "      <td>(0.09, 0.03, 0.04)</td>\n",
       "      <td>(0.37, 0.17, 0.24)</td>\n",
       "      <td>(0.33, 0.17, 0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.11, 0.23, 0.15)</td>\n",
       "      <td>(0.5, 0.19, 0.28)</td>\n",
       "      <td>(0.31, 0.15, 0.21)</td>\n",
       "      <td>(0.31, 0.15, 0.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.06, 0.19, 0.09)</td>\n",
       "      <td>(0.18, 0.07, 0.1)</td>\n",
       "      <td>(0.23, 0.16, 0.19)</td>\n",
       "      <td>(0.23, 0.16, 0.19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.11, 0.14, 0.13)</td>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>(0.17, 0.07, 0.1)</td>\n",
       "      <td>(0.29, 0.07, 0.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(0.05, 0.29, 0.08)</td>\n",
       "      <td>(0.11, 0.09, 0.1)</td>\n",
       "      <td>(0.14, 0.21, 0.17)</td>\n",
       "      <td>(0.14, 0.21, 0.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(0.12, 0.24, 0.16)</td>\n",
       "      <td>(0.38, 0.1, 0.16)</td>\n",
       "      <td>(0.44, 0.16, 0.23)</td>\n",
       "      <td>(0.42, 0.16, 0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(0.07, 0.26, 0.12)</td>\n",
       "      <td>(0.17, 0.08, 0.11)</td>\n",
       "      <td>(0.2, 0.16, 0.18)</td>\n",
       "      <td>(0.19, 0.16, 0.18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(0.08, 0.09, 0.09)</td>\n",
       "      <td>(0.8, 0.07, 0.14)</td>\n",
       "      <td>(0.42, 0.15, 0.22)</td>\n",
       "      <td>(0.42, 0.15, 0.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(0.14, 0.15, 0.14)</td>\n",
       "      <td>(0.25, 0.01, 0.03)</td>\n",
       "      <td>(0.3, 0.1, 0.15)</td>\n",
       "      <td>(0.23, 0.07, 0.11)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            мой способ                rake            TextRank  \\\n",
       "0   (0.09, 0.21, 0.13)           (0, 0, 0)  (0.24, 0.11, 0.15)   \n",
       "1   (0.17, 0.17, 0.17)   (0.67, 0.1, 0.17)  (0.23, 0.07, 0.11)   \n",
       "2   (0.08, 0.27, 0.12)  (0.31, 0.12, 0.17)  (0.47, 0.24, 0.32)   \n",
       "3   (0.17, 0.19, 0.18)   (0.67, 0.06, 0.1)  (0.25, 0.06, 0.09)   \n",
       "4   (0.05, 0.18, 0.08)  (0.11, 0.06, 0.08)  (0.06, 0.06, 0.06)   \n",
       "5   (0.02, 0.12, 0.04)   (0.1, 0.05, 0.07)   (0.07, 0.1, 0.09)   \n",
       "6    (0.1, 0.23, 0.14)  (0.09, 0.03, 0.04)  (0.37, 0.17, 0.24)   \n",
       "7   (0.11, 0.23, 0.15)   (0.5, 0.19, 0.28)  (0.31, 0.15, 0.21)   \n",
       "8   (0.06, 0.19, 0.09)   (0.18, 0.07, 0.1)  (0.23, 0.16, 0.19)   \n",
       "9   (0.11, 0.14, 0.13)           (0, 0, 0)   (0.17, 0.07, 0.1)   \n",
       "10  (0.05, 0.29, 0.08)   (0.11, 0.09, 0.1)  (0.14, 0.21, 0.17)   \n",
       "11  (0.12, 0.24, 0.16)   (0.38, 0.1, 0.16)  (0.44, 0.16, 0.23)   \n",
       "12  (0.07, 0.26, 0.12)  (0.17, 0.08, 0.11)   (0.2, 0.16, 0.18)   \n",
       "13  (0.08, 0.09, 0.09)   (0.8, 0.07, 0.14)  (0.42, 0.15, 0.22)   \n",
       "14  (0.14, 0.15, 0.14)  (0.25, 0.01, 0.03)    (0.3, 0.1, 0.15)   \n",
       "\n",
       "                 summa  \n",
       "0   (0.25, 0.11, 0.15)  \n",
       "1    (0.4, 0.14, 0.21)  \n",
       "2   (0.43, 0.27, 0.33)  \n",
       "3   (0.38, 0.08, 0.14)  \n",
       "4   (0.06, 0.06, 0.06)  \n",
       "5    (0.08, 0.1, 0.09)  \n",
       "6   (0.33, 0.17, 0.23)  \n",
       "7   (0.31, 0.15, 0.21)  \n",
       "8   (0.23, 0.16, 0.19)  \n",
       "9   (0.29, 0.07, 0.11)  \n",
       "10  (0.14, 0.21, 0.17)  \n",
       "11  (0.42, 0.16, 0.23)  \n",
       "12  (0.19, 0.16, 0.18)  \n",
       "13  (0.42, 0.15, 0.22)  \n",
       "14  (0.23, 0.07, 0.11)  "
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не все метрики хорошо работают с именами собственными, часто имя выделяется отдельно от фамилии, несмотря на то, что эти два слова состоят в одной именной группе. Это решается простым добавлением дополнительного фильтра PROPN + PROPN\n",
    "\n",
    "при разметке могут допускаться опечатки, необходимо резметку проверять спеллчекером\n",
    "\n",
    "в разметке встречались длинные отрывки фраз, это плохо потому что такие примеры при значении maxWords <= 3 не отлавливатся, а если это значение увеличивать, то будет попадать много мусорных примеров и понизятся значения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled22.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
